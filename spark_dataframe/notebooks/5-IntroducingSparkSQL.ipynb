{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing airline data with Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Analyzing airline data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring SQL query options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe with different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record = sc.parallelize([Row(id = 1,\n",
    "                             name = \"Jill\",\n",
    "                             active = True,\n",
    "                             clubs = ['chess', 'hockey'],\n",
    "                             subjects = {\"math\": 80, 'english': 56},\n",
    "                             enrolled = datetime(2014, 8, 1, 14, 1, 5)),\n",
    "                         Row(id = 2,\n",
    "                             name = \"George\",\n",
    "                             active = False,\n",
    "                             clubs = ['chess', 'soccer'],\n",
    "                             subjects = {\"math\": 60, 'english': 96},\n",
    "                             enrolled = datetime(2015, 3, 21, 8, 2, 5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "|active|          clubs|           enrolled| id|  name|            subjects|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "|  true|[chess, hockey]|2014-08-01 14:01:05|  1|  Jill|[english -> 56, m...|\n",
      "| false|[chess, soccer]|2015-03-21 08:02:05|  2|George|[english -> 96, m...|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record_df = record.toDF()\n",
    "record_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register the dataframe as a temporary view\n",
    "\n",
    "* The view is valid for one session\n",
    "* This is required to run SQL commands on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record_df.createOrReplaceTempView(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "|active|          clubs|           enrolled| id|  name|            subjects|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "|  true|[chess, hockey]|2014-08-01 14:01:05|  1|  Jill|[english -> 56, m...|\n",
      "| false|[chess, soccer]|2015-03-21 08:02:05|  2|George|[english -> 96, m...|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_records_df = sqlContext.sql('SELECT * FROM records')\n",
    "\n",
    "all_records_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----------------+\n",
      "| id|clubs[1]|subjects[english]|\n",
      "+---+--------+-----------------+\n",
      "|  1|  hockey|               56|\n",
      "|  2|  soccer|               96|\n",
      "+---+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT id, clubs[1], subjects[\"english\"] FROM records').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|(NOT active)|\n",
      "+---+------------+\n",
      "|  1|       false|\n",
      "|  2|        true|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT id, NOT active FROM records').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional statements in SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------------------+---+----+--------------------+\n",
      "|active|          clubs|           enrolled| id|name|            subjects|\n",
      "+------+---------------+-------------------+---+----+--------------------+\n",
      "|  true|[chess, hockey]|2014-08-01 14:01:05|  1|Jill|[english -> 56, m...|\n",
      "+------+---------------+-------------------+---+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT * FROM records where active').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "|active|          clubs|           enrolled| id|  name|            subjects|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "| false|[chess, soccer]|2015-03-21 08:02:05|  2|George|[english -> 96, m...|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT * FROM records where subjects[\"english\"] > 90').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global temporary view\n",
    "\n",
    "* Temporary view shared across multiple sessions\n",
    "* Kept alive till the Spark application terminates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record_df.createGlobalTempView(\"global_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "|active|          clubs|           enrolled| id|  name|            subjects|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "|  true|[chess, hockey]|2014-08-01 14:01:05|  1|  Jill|[english -> 56, m...|\n",
      "| false|[chess, soccer]|2015-03-21 08:02:05|  2|George|[english -> 96, m...|\n",
      "+------+---------------+-------------------+---+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT * FROM global_temp.global_records').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Working on external dataset with SQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlinesPath = \"datasets/airlines.csv\"\n",
    "flightsPath = \"datasets/flights.csv\"\n",
    "airportsPath = \"datasets/airports.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading External Data As DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(airlinesPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines.createOrReplaceTempView(\"airlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| Code|         Description|\n",
      "+-----+--------------------+\n",
      "|19031|Mackey Internatio...|\n",
      "|19032|Munz Northern Air...|\n",
      "|19033|Cochise Airlines ...|\n",
      "|19034|Golden Gate Airli...|\n",
      "|19035|  Aeromech Inc.: RZZ|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM airlines\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights = spark.read\\\n",
    "               .format(\"csv\")\\\n",
    "               .option(\"header\", \"true\")\\\n",
    "               .load(flightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights.createOrReplaceTempView(\"flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'airlines',\n",
       " 'flight_number',\n",
       " 'origin',\n",
       " 'destination',\n",
       " 'departure',\n",
       " 'departure_delay',\n",
       " 'arrival',\n",
       " 'arrival_delay',\n",
       " 'air_time',\n",
       " 'distance']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using count function with python commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_count_py = flights.count()\n",
    "airlines_count_py = airlines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476881, 1579)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count_py, airlines_count_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using count function with SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_count = spark.sql(\"SELECT COUNT(*) FROM flights\")\n",
    "airlines_count = spark.sql(\"SELECT COUNT(*) FROM airlines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Count( ) Using SQL Query Doesnt Return Integer, It Returns DataFrame **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[count(1): bigint], DataFrame[count(1): bigint])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count, airlines_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476881, 1579)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count.collect()[0][0], airlines_count.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_count = flights_count.collect()[0][0]\n",
    "airlines_count = airlines_count.collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding average distance of flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summation Of All The Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_distance_DF = spark.sql(\"SELECT distance FROM flights\")\\\n",
    "                         .agg({\"distance\":\"sum\"})\\\n",
    "                         .withColumnRenamed(\"sum(distance)\",\"total_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|total_distance|\n",
      "+--------------+\n",
      "|  3.79052917E8|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_distance_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_distance = total_distance_DF.collect()[0][0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Average Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794.8585013871385"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_distance = total_distance/flights.count()\n",
    "avg_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many flights got delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fligts With Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_delay = spark.sql(\"select airlines, flight_number, departure_delay from flights where departure_delay > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_delay.createOrReplaceTempView(\"all_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+---------------+\n",
      "|airlines|flight_number|departure_delay|\n",
      "+--------+-------------+---------------+\n",
      "|   20366|         5246|          99.00|\n",
      "|   19393|         2948|          99.00|\n",
      "|   20366|         5365|          99.00|\n",
      "|   19977|          616|          99.00|\n",
      "|   20366|         6030|          99.00|\n",
      "+--------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_delay.orderBy(all_delay.departure_delay.desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Number Of Flights Got Delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delay_count = spark.sql(\"SELECT COUNT(departure_delay) FROM all_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(departure_delay)|\n",
      "+----------------------+\n",
      "|                179015|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179015"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_count.collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many percent flights got delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.53871510922012"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_percent = delay_count.collect()[0][0] / flights_count * 100\n",
    "delay_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding delay per aIrlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delay_per_airline = spark.sql(\"SELECT airlines, departure_delay FROM flights\")\\\n",
    "                        .groupBy(\"airlines\")\\\n",
    "                        .agg({\"departure_delay\":\"avg\"})\\\n",
    "                        .withColumnRenamed(\"avg(departure_delay)\",\n",
    "                                           \"departure_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|airlines|   departure_delay|\n",
      "+--------+------------------+\n",
      "|   19393|13.429567657134724|\n",
      "|   20366|12.296210112379818|\n",
      "|   19977| 8.818392620527979|\n",
      "|   20436| 8.716275167785234|\n",
      "|   20409|  8.31110357194785|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_per_airline.orderBy(delay_per_airline.departure_delay.desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delay_per_airline.createOrReplaceTempView(\"delay_per_airline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delay_per_airline = spark.sql(\"SELECT * FROM delay_per_airline ORDER BY departure_delay DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|airlines|   departure_delay|\n",
      "+--------+------------------+\n",
      "|   19393|13.429567657134724|\n",
      "|   20366|12.296210112379818|\n",
      "|   19977| 8.818392620527979|\n",
      "|   20436| 8.716275167785234|\n",
      "|   20409|  8.31110357194785|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_per_airline.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Operation in SQL Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the number of airlines which have delay but we dont know thier names<br>\n",
    "We need to get their names from different DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----+--------------------+\n",
      "|airlines|    departure_delay| Code|         Description|\n",
      "+--------+-------------------+-----+--------------------+\n",
      "|   19690|-2.1981308411214955|19690|Hawaiian Airlines...|\n",
      "|   19930|-0.6991515343747522|19930|Alaska Airlines I...|\n",
      "|   20437|  5.110621095185594|20437|AirTran Airways C...|\n",
      "|   19393| 13.429567657134724|19393|Southwest Airline...|\n",
      "|   19977|  8.818392620527979|19977|United Air Lines ...|\n",
      "+--------+-------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM delay_per_airline JOIN airlines ON airlines.code = delay_per_airline.airlines\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: We are getting duplicate columns with different names** <br>\n",
    "      For this we need to drop unwanted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+--------------------+\n",
      "|airlines|    departure_delay|         Description|\n",
      "+--------+-------------------+--------------------+\n",
      "|   19690|-2.1981308411214955|Hawaiian Airlines...|\n",
      "|   19930|-0.6991515343747522|Alaska Airlines I...|\n",
      "|   20437|  5.110621095185594|AirTran Airways C...|\n",
      "|   19393| 13.429567657134724|Southwest Airline...|\n",
      "|   19977|  8.818392620527979|United Air Lines ...|\n",
      "+--------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM delay_per_airline JOIN airlines ON airlines.code = delay_per_airline.airlines\")\\\n",
    "     .drop(\"code\")\\\n",
    "     .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TODO: How many flights got delayed per airport\n",
    "* Find the airports with the worst and best delays\n",
    "* Average distance a flight travels from an airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding average distance travelled by flights per airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "airports = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(airportsPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Temp view\n",
    "airports.createOrReplaceTempView(\"airports\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_airport = spark.sql(\"SELECT origin,distance FROM flights\")\\\n",
    "                    .groupBy(\"origin\")\\\n",
    "                    .agg({\"distance\":\"avg\"})\\\n",
    "                    .withColumnRenamed(\"avg(distance)\",\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_airport.createOrReplaceTempView(\"dist_airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|origin|          distance|\n",
      "+------+------------------+\n",
      "|   GUM|            3801.0|\n",
      "|   PPG|            2599.0|\n",
      "|   BQN|1469.3361344537816|\n",
      "|   BLI|1455.5238095238096|\n",
      "|   JFK|1422.3096654275093|\n",
      "+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM dist_airport ORDER BY distance DESC\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|          distance|Code|         Description|\n",
      "+------------------+----+--------------------+\n",
      "|            3801.0| GUM|Guam, TT: Guam In...|\n",
      "|            2599.0| PPG|Pago Pago, TT: Pa...|\n",
      "|1469.3361344537816| BQN|Aguadilla, PR: Ra...|\n",
      "|1455.5238095238096| BLI|Bellingham, WA: B...|\n",
      "|1422.3096654275093| JFK|New York, NY: Joh...|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM dist_airport JOIN airports ON airports.code = dist_airport.origin ORDER BY distance DESC\")\\\n",
    "     .drop('origin')\\\n",
    "     .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### How many Flights got Delayed per Airport "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "* add percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_delay = spark.sql(\"SELECT origin, departure_delay FROM flights where departure_delay > 0\")\\\n",
    "                      .groupBy(\"origin\")\\\n",
    "                      .agg({\"departure_delay\":\"sum\"})\\\n",
    "                      .withColumnRenamed(\"sum(departure_delay)\",\"departure_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = flights.agg({\"departure_delay\":\"sum\"})\\\n",
    "               .collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_delay = total_delay.withColumn(\"percent\",\n",
    "                                     func.round(total_delay['departure_delay']/total * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_delay.createOrReplaceTempView(\"total_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------+\n",
      "|origin|departure_delay|percent|\n",
      "+------+---------------+-------+\n",
      "|   ORD|       326080.0|   8.22|\n",
      "|   ATL|       316740.0|   7.99|\n",
      "|   DFW|       235129.0|   5.93|\n",
      "|   DEN|       218359.0|   5.51|\n",
      "|   LAX|       194285.0|    4.9|\n",
      "+------+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM total_delay ORDER BY percent DESC\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------+\n",
      "|origin|departure_delay|percent|\n",
      "+------+---------------+-------+\n",
      "|   ADK|          143.0|    0.0|\n",
      "|   PSG|          140.0|    0.0|\n",
      "|   CDV|           69.0|    0.0|\n",
      "|   INL|          131.0|    0.0|\n",
      "|   WRG|           95.0|    0.0|\n",
      "+------+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM total_delay ORDER BY percent ASC\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Delays of Flight  from Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays_airport = spark.sql(\"SELECT origin, departure_delay FROM flights where departure_delay > 0\")\\\n",
    "                      .groupBy(\"origin\")\\\n",
    "                      .agg(func.avg('departure_delay')\\\n",
    "                      .alias('departure_delay'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|origin|   departure_delay|\n",
      "+------+------------------+\n",
      "|   INL|              26.2|\n",
      "|   PSE|             43.75|\n",
      "|   MSY|29.088963210702342|\n",
      "|   PPG|             116.5|\n",
      "|   GEG| 18.51497005988024|\n",
      "+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delays_airport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays_airport.createOrReplaceTempView(\"delays_airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|origin|  departure_delay|\n",
      "+------+-----------------+\n",
      "|   LMT|            123.5|\n",
      "|   PPG|            116.5|\n",
      "|   PAH|91.38461538461539|\n",
      "|   FAI|81.76923076923077|\n",
      "|   TWF|77.11111111111111|\n",
      "+------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delays_airport = spark.sql(\"SELECT * FROM delays_airport ORDER BY departure_delay DESC\")\n",
    "delays_airport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
